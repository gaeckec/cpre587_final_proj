{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Python Version: 3.6.8 (default, Aug 13 2020, 07:46:32) \n",
      "[GCC 4.8.5 20150623 (Red Hat 4.8.5-39)]\n",
      "Using Tensorflow Version: 2.6.2\n",
      "Running on CPU\n"
     ]
    }
   ],
   "source": [
    "import pathlib, os, sys, operator, re, datetime\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow_datasets as tfds\n",
    "from tiny_imagenet import TinyImagenetDataset\n",
    "\n",
    "# Enable or disable GPU\n",
    "# To fully disable it, we need to hide all GPU devices from Tensorflow\n",
    "# Make sure GPU is disabled for this inference part of the lab\n",
    "ENABLE_GPU = False\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "if not ENABLE_GPU:\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "# Print Python and TF version, and where we are running\n",
    "print(f'Running on Python Version: {sys.version}')\n",
    "print(f'Using Tensorflow Version: {tf. __version__}')\n",
    "if not tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    print('Running on CPU')\n",
    "else:\n",
    "    print(f'Using GPU at: {tf.test.gpu_device_name()} (of {len(tf.config.experimental.list_physical_devices(\"GPU\"))} available)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Normalize the images\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "# Original Source: https://github.com/ksachdeva/tiny-imagenet-tfds\n",
    "# Class Version Source: https://github.com/Mluckydwyer/tiny-imagenet-tfds\n",
    "# Setup our dataset\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "tiny_imagenet_builder = TinyImagenetDataset()\n",
    "\n",
    "# this call (download_and_prepare) will trigger the download of the dataset\n",
    "# and preparation (conversion to tfrecords)\n",
    "#\n",
    "# This will be done only once and on next usage tfds will\n",
    "# use the cached version on your host.\n",
    "tiny_imagenet_builder.download_and_prepare(download_dir=\"~/tensorflow-datasets/downloads\")\n",
    "\n",
    "# class_names = tiny_imagenet_builder.info.features['label'].names\n",
    "ds = tiny_imagenet_builder.as_dataset()\n",
    "ds_train, ds_val = ds[\"train\"], ds[\"validation\"]\n",
    "assert(isinstance(ds_train, tf.data.Dataset))\n",
    "assert(isinstance(ds_val, tf.data.Dataset))\n",
    "\n",
    "# Training Dataset\n",
    "# ds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.shuffle(1024).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "# Validation Dataset\n",
    "# ds_val = ds_val.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_val_small = ds_val.shuffle(1024).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "# Dataset metadata\n",
    "ds_info = tiny_imagenet_builder.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/kenkelj/cpre587/Lab4/wnids.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d6fa78126b00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# We need to read the \"human readable\" labels so we can translate with the numeric values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Read the labels file (words.txt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wnids.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mwnids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/kenkelj/cpre587/Lab4/wnids.txt'"
     ]
    }
   ],
   "source": [
    "# We need to read the \"human readable\" labels so we can translate with the numeric values\n",
    "# Read the labels file (words.txt)\n",
    "with open(os.path.abspath('wnids.txt'), 'r') as f:\n",
    "    wnids = [x.strip() for x in f]\n",
    "\n",
    "# Map wnids to integer labels\n",
    "wnid_to_label = {wnid: i for i, wnid in enumerate(wnids)}\n",
    "label_to_wnid = {v: k for k, v in wnid_to_label.items()}\n",
    "\n",
    "# Use words.txt to get names for each class\n",
    "with open(os.path.abspath('words.txt'), 'r') as f:\n",
    "    wnid_to_words = dict(line.split('\\t') for line in f)\n",
    "    for wnid, words in wnid_to_words.items():\n",
    "        wnid_to_words[wnid] = [w.strip() for w in words.split(',')]\n",
    "        \n",
    "class_names = [str(wnid_to_words[wnid]) for wnid in wnids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-043b2f4070cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mhist_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhist_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist_data = np.arange(1)\n",
    "for img_idx, img in enumerate(ds_train.batch(1)):\n",
    "    data = np.asarray(img[\"image\"]).astype('float32').flatten() / 255.0\n",
    "    hist_data = np.concatenate([hist_data, data], axis = 0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bin_num = 800;\n",
    "\n",
    "# Creating histogram\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "ax.hist(hist_data, bins = bin_num)\n",
    " \n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: /home/kenkelj/cpre587/Lab4/CNN_TinyImageNet_2.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4dc87fbe0236>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# TODO: Your Code Here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cpre587/venv/lib64/python3.6/site-packages/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m   raise IOError(\n",
      "\u001b[0;32m~/cpre587/venv/lib64/python3.6/site-packages/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, compile, options)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;31m# Look for metadata file or parse the SavedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_metadata_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSavedMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m   \u001b[0mmeta_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_graphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m   \u001b[0mobject_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_graph_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mpath_to_metadata_pb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_METADATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cpre587/venv/lib64/python3.6/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;34m\"SavedModel file does not exist at: %s%s{%s|%s}\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         (export_dir, os.path.sep, constants.SAVED_MODEL_FILENAME_PBTXT,\n\u001b[0;32m--> 121\u001b[0;31m          constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: /home/kenkelj/cpre587/Lab4/CNN_TinyImageNet_2.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ef573b48ea35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_val_small\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mget_relu_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mrelu_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_relu_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# model_path = os.path.abspath(\"\"/home/dwyer/482/dev/CNN_TinyImageNet_2.h5)\" # Uncomment this to use a non-relative path\n",
    "model_path = os.path.abspath(\"CNN_TinyImageNet_2.h5\")\n",
    "\n",
    "# TODO: Your Code Here\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# model\n",
    "# get_relu_output = K.function([model.layers[0].input], [model.layers[0].output])\n",
    "ds_val_small = ds_val.shuffle(1024).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "\n",
    "for img_idx, img in enumerate(ds_val_small.batch(1)):\n",
    "    get_relu_output = K.function([model.layers[0].input], [model.layers[0].output])\n",
    "    relu_output = get_relu_output([img])\n",
    "    print(relu_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c5c62ceb5bd4bed07c1546be8df8af91143d8f70a1047003210034f65d0e85b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
